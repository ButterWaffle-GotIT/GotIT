{
	"id": 4098,
	"slug": "rag",
	"term": { "ko": "RAG", "en": "RAG" },
	"aliases": ["검색 증강 생성", "Retrieval Augmented Generation"],
	"summary": "LLM이 응답을 생성하기 전에, 외부 데이터베이스나 문서에서 최신 정보를 검색하여 답변의 정확성을 높이는 아키텍처 패턴.",
	"onelinerForNonTech": "AI가 머릿속 지식만으로 답하는 것이 아니라, 대답하기 전에 '도서관'에서 가장 최신 자료를 찾아보고 답하게 하는 방식.",
	"description": "RAG는 LLM의 가장 큰 문제점인 '환각(Hallucination)' 현상을 줄이고, 학습 데이터에 없던 최신 정보를 반영할 수 있게 한다. 사용자의 질문을 벡터로 변환하고, 벡터 데이터베이스에서 관련 문서를 검색한 후, 이 문서를 프롬프트에 포함하여 LLM에게 전달하는 방식으로 작동한다. LLM을 엔터프라이즈 환경에 적용하는 데 필수적이다.",
	"tags": ["AI", "데이터", "백엔드"],
	"primaryTag": "AI",
	"relatedIds": [4010, 4081, 4097],
	"confusableIds": [4010],
	"useCases": [
		{ "role": "Dev", "text": "회사 내부 지침에 관한 질문에는 RAG 시스템을 통해 답변의 신뢰도를 확보해야 합니다." },
		{ "role": "PM", "text": "RAG를 도입하여 AI 챗봇이 최신 제품 설명서를 기반으로 답변하도록 개선합시다." }
	],
	"keywords": ["rag", "검색증강", "retrieval", "llm", "환각", "벡터"],
	"level": "intermediate",
	"updatedAt": "2025-11-30"
}
